"""
BENCHMARK.PY - –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π
"""

import os
import time
import pandas as pd
import streamlit as st
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import numpy as np
from datetime import datetime
import json
import warnings
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import random

warnings.filterwarnings('ignore')

class EnhancedModelBenchmark:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
    
    def __init__(self, test_emails_dir: str = "test_emails"):
        self.test_emails_dir = Path(test_emails_dir)
        self.results_history = []
        
        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –ª–æ–≥–æ–≤
        self.logs_dir = Path("benchmark_logs")
        self.logs_dir.mkdir(exist_ok=True)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.config = {
            "min_text_length": 50,
            "max_text_length": 10000,
            "default_threshold": 0.15,  # –ü–æ–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥
            "max_emails": 500,
            "cache_enabled": True,
            "save_detailed_results": True
        }
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—ë–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –ø–∞–ø–∫–∏ –Ω–µ—Ç
        if not self.test_emails_dir.exists():
            self._create_enhanced_demo_structure()
    
    def _create_enhanced_demo_structure(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö"""
        self.test_emails_dir.mkdir(exist_ok=True)
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏
        category_templates = {
            "–î–µ–ª–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ": [
                "–£–≤–∞–∂–∞–µ–º—ã–π –ø–∞—Ä—Ç–Ω—ë—Ä! –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤–∞–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞ –≤ —Å—Ñ–µ—Ä–µ IT-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏. –ù–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è –≥–æ—Ç–æ–≤–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è. –ë—É–¥–µ–º —Ä–∞–¥—ã –æ–±—Å—É–¥–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –Ω–∞ –ª–∏—á–Ω–æ–π –≤—Å—Ç—Ä–µ—á–µ.\n\n–° —É–≤–∞–∂–µ–Ω–∏–µ–º,\n–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤\n–î–∏—Ä–µ–∫—Ç–æ—Ä –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é",
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ö–æ–º–ø–∞–Ω–∏—è '–¢–µ—Ö–Ω–æ–ò–Ω–Ω–æ–≤–∞—Ü–∏–∏' –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–æ –≤ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –ì–æ—Ç–æ–≤—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞. –ü—Ä–æ—Å–∏–º –Ω–∞–ø—Ä–∞–≤–∏—Ç—å –≤–∞—à–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ –∫–æ–Ω—Ü–∞ –Ω–µ–¥–µ–ª–∏.",
                "–î–æ–±—Ä—ã–π –¥–µ–Ω—å! –ù–∞–ø—Ä–∞–≤–ª—è–µ–º –≤–∞–º –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ –ø–æ—Å—Ç–∞–≤–∫–µ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤. –í –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –≤—ã –Ω–∞–π–¥—ë—Ç–µ –¥–µ—Ç–∞–ª–∏ —Ç–∞—Ä–∏—Ñ–æ–≤ –∏ —É—Å–ª–æ–≤–∏–π —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞. –ñ–¥—ë–º –≤–∞—à–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π."
            ],
            "–ñ–∞–ª–æ–±–∞ –∫–ª–∏–µ–Ω—Ç–∞": [
                "–£–≤–∞–∂–∞–µ–º–∞—è —Å–ª—É–∂–±–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏! –Ø –∫—Ä–∞–π–Ω–µ –Ω–µ–¥–æ–≤–æ–ª–µ–Ω –∫–∞—á–µ—Å—Ç–≤–æ–º –≤–∞—à–µ–≥–æ —Å–µ—Ä–≤–∏—Å–∞. –í—á–µ—Ä–∞ —Å–∏—Å—Ç–µ–º–∞ –±—ã–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –±–æ–ª–µ–µ 3 —á–∞—Å–æ–≤, —á—Ç–æ –ø—Ä–∏–≤–µ–ª–æ –∫ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º –ø–æ—Ç–µ—Ä—è–º –≤ —Ä–∞–∑–º–µ—Ä–µ 50,000 —Ä—É–±–ª–µ–π. –¢—Ä–µ–±—É—é –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã –∏ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏ —É—â–µ—Ä–±–∞.\n\n–° –Ω–µ—Ç–µ—Ä–ø–µ–Ω–∏–µ–º –∂–¥—É –æ—Ç–≤–µ—Ç–∞,\n–ê–ª–µ–∫—Å–µ–π –°–∏–¥–æ—Ä–æ–≤",
                "–î–æ–±—Ä—ã–π –¥–µ–Ω—å! –≠—Ç–æ —É–∂–µ —Ç—Ä–µ—Ç—å—è –∂–∞–ª–æ–±–∞ –∑–∞ –º–µ—Å—è—Ü. –í–∞—à –ø—Ä–æ–¥—É–∫—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤—ã—Ö–æ–¥–∏—Ç –∏–∑ —Å—Ç—Ä–æ—è, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç. –¢—Ä–µ–±—É—é —Å—Ä–æ—á–Ω–æ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –∏ —Ä–µ—à–µ–Ω–∏—è –≤—Å–µ—Ö –Ω–∞–∫–æ–ø–∏–≤—à–∏—Ö—Å—è –ø—Ä–æ–±–ª–µ–º.",
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ü–∏—Å—å–º–æ-–ø—Ä–µ—Ç–µ–Ω–∑–∏—è –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É ‚Ññ2345. –£–≤–µ–¥–æ–º–ª—è—é –æ –Ω–∞—Ä—É—à–µ–Ω–∏–∏ —Å—Ä–æ–∫–æ–≤ –ø–æ—Å—Ç–∞–≤–∫–∏ –Ω–∞ 2 –Ω–µ–¥–µ–ª–∏. –¢—Ä–µ–±—É—é –≤—ã–ø–ª–∞—Ç—ã –Ω–µ—É—Å—Ç–æ–π–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –ø—É–Ω–∫—Ç—É 5.3 –¥–æ–≥–æ–≤–æ—Ä–∞."
            ],
            "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞": [
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ù–µ –º–æ–≥—É –≤–æ–π—Ç–∏ –≤ –ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç —Å 10:00 —É—Ç—Ä–∞. –ü—Ä–∏ –≤–≤–æ–¥–µ –ª–æ–≥–∏–Ω–∞ –∏ –ø–∞—Ä–æ–ª—è –ø–æ–ª—É—á–∞—é –æ—à–∏–±–∫—É '500 Internal Server Error'. –ü—Ä–æ–±–æ–≤–∞–ª –æ—á–∏—Å—Ç–∏—Ç—å –∫—ç—à, —Å–º–µ–Ω–∏—Ç—å –±—Ä–∞—É–∑–µ—Ä ‚Äî –Ω–µ –ø–æ–º–æ–≥–∞–µ—Ç.\n\n–ü—Ä–æ—à—É –ø–æ–º–æ—á—å —Å —Ä–µ—à–µ–Ω–∏–µ–º –ø—Ä–æ–±–ª–µ–º—ã.\n–ê–Ω–Ω–∞ –ö.",
                "–î–æ–±—Ä—ã–π –¥–µ–Ω—å! –í–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π. –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ endpoint /api/v1/data –ø–æ–ª—É—á–∞—é —Å—Ç–∞—Ç—É—Å 401. –ü—Ä–æ–≤–µ—Ä–∏–ª —Ç–æ–∫–µ–Ω—ã ‚Äî –≤—Å—ë –≤ –ø–æ—Ä—è–¥–∫–µ. –ù—É–∂–Ω–∞ —Å—Ä–æ—á–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–º–æ—â—å.",
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –°–æ–æ–±—â–∞—é –æ –±–∞–≥–µ –≤ –º–æ–±–∏–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –≤–µ—Ä—Å–∏–∏ 2.3.1. –ù–∞ iOS 16 –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∫—Ä–∞—à–∏—Ç—Å—è. –õ–æ–≥–∏ –ø—Ä–∏–ª–∞–≥–∞—é."
            ],
            "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å": [
                "–£–≤–∞–∂–∞–µ–º—ã–µ –∫–æ–ª–ª–µ–≥–∏! –ü—Ä–æ—à—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ —Å—á–µ—Ç—É ‚ÑñINV-2024-001 –∑–∞ —è–Ω–≤–∞—Ä—å 2024 –≥–æ–¥–∞, –∞ —Ç–∞–∫–∂–µ —É—Ç–æ—á–Ω–∏—Ç—å —Å—Ä–æ–∫–∏ –æ–ø–ª–∞—Ç—ã –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É ‚Ññ5678.\n\n–° —É–≤–∞–∂–µ–Ω–∏–µ–º,\n–ú–∞—Ä–∏—è –ò–≤–∞–Ω–æ–≤–∞\n–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç–¥–µ–ª",
                "–î–æ–±—Ä—ã–π –¥–µ–Ω—å! –ù–∞–ø—Ä–∞–≤–ª—è–µ–º —Å—á—ë—Ç –Ω–∞ –æ–ø–ª–∞—Ç—É —É—Å–ª—É–≥ –∑–∞ –¥–µ–∫–∞–±—Ä—å 2023. –°—É–º–º–∞: 150,000 —Ä—É–±–ª–µ–π. –°—Ä–æ–∫ –æ–ø–ª–∞—Ç–∞: 10 —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π. –ü—Ä–æ—Å–∏–º –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ.",
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ó–∞–ø—Ä–æ—Å –Ω–∞ –≤–æ–∑–≤—Ä–∞—Ç —Å—Ä–µ–¥—Å—Ç–≤ –ø–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ ‚ÑñTRX-789456 –æ—Ç 15.01.2024. –°—É–º–º–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞: 25,000 —Ä—É–±–ª–µ–π. –ü—Ä–∏—á–∏–Ω–∞: –¥–≤–æ–π–Ω–æ–µ —Å–ø–∏—Å–∞–Ω–∏–µ."
            ],
            "–°–ø–∞–º / –†–µ–∫–ª–∞–º–∞": [
                "üéâ –ü–û–ó–î–†–ê–í–õ–Ø–ï–ú! –í–´ –í–´–ò–ì–†–ê–õ–ò 1 000 000 –†–£–ë–õ–ï–ô! üéâ\n\n–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–∏–∑–∞ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ —Å—Å—ã–ª–∫–µ: http://super-prize.ru/win\n\n‚ùó –ê–ö–¶–ò–Ø –î–ï–ô–°–¢–í–£–ï–¢ –¢–û–õ–¨–ö–û 24 –ß–ê–°–ê! ‚ùó\n\n–ù–µ —É–ø—É—Å—Ç–∏—Ç–µ —Å–≤–æ–π —à–∞–Ω—Å —Å—Ç–∞—Ç—å –º–∏–ª–ª–∏–æ–Ω–µ—Ä–æ–º!",
                "–°–†–û–ß–ù–û! –°–ö–ò–î–ö–ê 70% –ù–ê –í–°–ï –ö–£–†–°–´!\n\n–¢–æ–ª—å–∫–æ –¥–æ –∫–æ–Ω—Ü–∞ –Ω–µ–¥–µ–ª–∏! –£—Å–ø–µ–π—Ç–µ –∫—É–ø–∏—Ç—å –∫—É—Ä—Å—ã –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é —Å–æ —Å–∫–∏–¥–∫–æ–π 70%!\n\n–ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ: http://best-courses.ru/discount\n\n–ù–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —É–Ω–∏–∫–∞–ª—å–Ω—É—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å!",
                "–í–´ –í–´–ò–ì–†–ê–õ–ò IPHONE 15 PRO MAX!\n\n–í–∞—à –Ω–æ–º–µ—Ä –æ–∫–∞–∑–∞–ª—Å—è —Å—á–∞—Å—Ç–ª–∏–≤—ã–º! –ó–∞–±–µ—Ä–∏—Ç–µ —Å–≤–æ–π –ø—Ä–∏–∑: http://iphone-giveaway.ru/claim\n\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 100 —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤!"
            ],
            "HR / –†–µ–∫—Ä—É—Ç–∏–Ω–≥": [
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –ò–≤–∞–Ω! –ú—ã –æ–∑–Ω–∞–∫–æ–º–∏–ª–∏—Å—å —Å –≤–∞—à–∏–º —Ä–µ–∑—é–º–µ –Ω–∞ HH.ru –∏ —Ö–æ—Ç–µ–ª–∏ –±—ã –ø—Ä–∏–≥–ª–∞—Å–∏—Ç—å –≤–∞—Å –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø–æ–∑–∏—Ü–∏—é Senior Python Developer.\n\n–î–∞—Ç–∞: 25 —è–Ω–≤–∞—Ä—è 2024\n–í—Ä–µ–º—è: 15:00\n–§–æ—Ä–º–∞—Ç: –æ–Ω–ª–∞–π–Ω (Zoom)\n\n–°—Å—ã–ª–∫–∞ –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: https://zoom.us/j/123456789\n\n–ñ–¥—ë–º –≤–∞—Å!\n\n–° —É–≤–∞–∂–µ–Ω–∏–µ–º,\n–ê–Ω–Ω–∞, —Ä–µ–∫—Ä—É—Ç–µ—Ä",
                "–î–æ–±—Ä—ã–π –¥–µ–Ω—å! –ö–æ–º–ø–∞–Ω–∏—è '–¢–µ—Ö–Ω–æ–õ–∞–±' –∏—â–µ—Ç Data Scientist. –£–≤–∏–¥–µ–ª–∏ –≤–∞—à –ø—Ä–æ—Ñ–∏–ª—å –Ω–∞ LinkedIn. –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –æ–±—Å—É–¥–∏—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞.\n\n–ó–∞—Ä–ø–ª–∞—Ç–Ω–∞—è –≤–∏–ª–∫–∞: 250,000 - 350,000 —Ä—É–±–ª–µ–π\n–§–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã: –≥–∏–±—Ä–∏–¥–Ω—ã–π\n\n–ì–æ—Ç–æ–≤—ã –æ–±—Å—É–¥–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –≤ —É–¥–æ–±–Ω–æ–µ –¥–ª—è –≤–∞—Å –≤—Ä–µ–º—è.",
                "–ü—Ä–∏–≤–µ—Ç! –í–∏–¥–µ–ª —Ç–≤–æ—ë –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ –Ω–∞ GitHub. –£ –Ω–∞—Å –≤ —Å—Ç–∞—Ä—Ç–∞–ø–µ –æ—Ç–∫—Ä—ã—Ç–∞ –≤–∞–∫–∞–Ω—Å–∏—è ML Engineer. –ò–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?"
            ],
            "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ø–∏—Å—å–º–æ": [
                "–£–í–ï–î–û–ú–õ–ï–ù–ò–ï –û –ù–ê–†–£–®–ï–ù–ò–ò –î–û–ì–û–í–û–†–ê\n\n–î–æ–≥–æ–≤–æ—Ä ‚Ññ123-456 –æ—Ç 15.01.2023\n\n–ù–∞—Å—Ç–æ—è—â–∏–º —É–≤–µ–¥–æ–º–ª—è–µ–º, —á—Ç–æ –≤–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è –Ω–∞—Ä—É—à–∏–ª–∞ –ø—É–Ω–∫—Ç 4.2 –î–æ–≥–æ–≤–æ—Ä–∞ –æ –ø–æ—Å—Ç–∞–≤–∫–µ —Ç–æ–≤–∞—Ä–æ–≤. –¢—Ä–µ–±—É–µ–º —É—Å—Ç—Ä–∞–Ω–∏—Ç—å –Ω–∞—Ä—É—à–µ–Ω–∏—è –≤ —Ç–µ—á–µ–Ω–∏–µ 10 —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π.\n\n–í —Å–ª—É—á–∞–µ –Ω–µ–∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –±—É–¥–µ–º –≤—ã–Ω—É–∂–¥–µ–Ω—ã –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ —Å—É–¥.\n\n–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –æ—Ç–¥–µ–ª\n–û–û–û '–ü—Ä–∞–≤–æ–ì–∞—Ä–∞–Ω—Ç'",
                "–ü–†–ï–¢–ï–ù–ó–ò–Ø\n\n–ü–æ –¥–æ–≥–æ–≤–æ—Ä—É –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥ ‚Ññ789 –æ—Ç 20.12.2023\n\n–ù–∞–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ—Ç–µ–Ω–∑–∏—é –≤ —Å–≤—è–∑–∏ —Å –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –æ–∫–∞–∑–∞–Ω–∏–µ–º —É—Å–ª—É–≥. –¢—Ä–µ–±—É–µ–º:\n1. –£—Å—Ç—Ä–∞–Ω–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏\n2. –í—ã–ø–ª–∞—Ç–∏—Ç—å –Ω–µ—É—Å—Ç–æ–π–∫—É\n3. –ö–æ–º–ø–µ–Ω—Å–∏—Ä–æ–≤–∞—Ç—å —É–±—ã—Ç–∫–∏\n\n–°—Ä–æ–∫ –æ—Ç–≤–µ—Ç–∞: 5 –¥–Ω–µ–π.",
                "–ò–°–ö–û–í–û–ï –ó–ê–Ø–í–õ–ï–ù–ò–ï\n\n–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –∏—Å–∫–æ–≤–æ–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ –æ –≤–∑—ã—Å–∫–∞–Ω–∏–∏ –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É ‚Ññ456. –°—É–º–º–∞ –∏—Å–∫–∞: 1,500,000 —Ä—É–±–ª–µ–π.\n\n–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º —É—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –≤ –¥–æ—Å—É–¥–µ–±–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ."
            ],
            "–ù–æ–≤–æ—Å—Ç–∏ / –ê–Ω–æ–Ω—Å—ã": [
                "–î–æ—Ä–æ–≥–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏! üéä\n\n–†–∞–¥—ã —Å–æ–æ–±—â–∏—Ç—å –æ –∑–∞–ø—É—Å–∫–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã 3.0!\n\n–û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:\n‚Ä¢ –£—Å–∫–æ—Ä–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –Ω–∞ 40%\n‚Ä¢ –°–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–æ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å\n‚Ä¢ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏\n‚Ä¢ –£–ª—É—á—à–µ–Ω–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\n\n–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ —Å 1 —Ñ–µ–≤—Ä–∞–ª—è.\n\n–° —É–≤–∞–∂–µ–Ω–∏–µ–º,\n–ö–æ–º–∞–Ω–¥–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
                "–í–ê–ñ–ù–û–ï –û–ë–™–Ø–í–õ–ï–ù–ò–ï\n\n–£–≤–µ–¥–æ–º–ª—è–µ–º –æ –ø–ª–∞–Ω–æ–≤—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ä–∞–±–æ—Ç–∞—Ö 25 —è–Ω–≤–∞—Ä—è —Å 02:00 –¥–æ 06:00 –ú–°–ö.\n\n–í —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥ –≤–æ–∑–º–æ–∂–Ω—ã –ø–µ—Ä–µ–±–æ–∏ –≤ —Ä–∞–±–æ—Ç–µ —Å–µ—Ä–≤–∏—Å–∞.\n\n–ü—Ä–∏–Ω–æ—Å–∏–º –∏–∑–≤–∏–Ω–µ–Ω–∏—è –∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–µ—É–¥–æ–±—Å—Ç–≤–∞.",
                "–ê–ù–û–ù–°: –í–µ–±–∏–Ω–∞—Ä '–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ –±–∏–∑–Ω–µ—Å–µ'\n\n–î–∞—Ç–∞: 30 —è–Ω–≤–∞—Ä—è 2024\n–í—Ä–µ–º—è: 19:00 –ú–°–ö\n–°–ø–∏–∫–µ—Ä: –î–º–∏—Ç—Ä–∏–π –°–º–∏—Ä–Ω–æ–≤, CEO AI Solutions\n\n–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è: http://webinar.ai/register"
            ],
            "–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ / –ü—Ä–æ–¥–∞–∂–∏": [
                "–°–ü–ï–¶–ò–ê–õ–¨–ù–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï –î–õ–Ø –í–ê–°! ‚ú®\n\n–¢–æ–ª—å–∫–æ –¥–ª—è –Ω–∞—à–∏—Ö –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ ‚Äî —Å–∫–∏–¥–∫–∞ 30% –Ω–∞ –≤—Å–µ –∫—É—Ä—Å—ã –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –¥–æ –∫–æ–Ω—Ü–∞ –º–µ—Å—è—Ü–∞!\n\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ–º–æ–∫–æ–¥: SALE30\n\n–ù–µ —É–ø—É—Å—Ç–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–≤—ã—Å–∏—Ç—å —Å–≤–æ–∏ –Ω–∞–≤—ã–∫–∏!\n\n–ó–∞–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å —Å–µ–π—á–∞—Å: http://courses.com",
                "–£–í–ï–õ–ò–ß–¨–¢–ï –ü–†–û–î–ê–ñ–ò –ù–ê 200% –° –ù–ê–®–ò–ú –†–ï–®–ï–ù–ò–ï–ú!\n\n–ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é CRM-—Å–∏—Å—Ç–µ–º—É —Å AI-–∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π.\n\n–ü–µ—Ä–≤—ã–π –º–µ—Å—è—Ü –±–µ—Å–ø–ª–∞—Ç–Ω–æ!\n\n–ó–∞–∫–∞–∂–∏—Ç–µ –¥–µ–º–æ: http://crm-ai.ru/demo",
                "–†–ê–°–ü–†–û–î–ê–ñ–ê –°–ö–õ–ê–î–ê!\n\n–°–Ω–∏–∂–∞–µ–º —Ü–µ–Ω—ã –Ω–∞ –≤—Å—ë –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ –Ω–∞ 50%!\n\n–¢–æ–ª—å–∫–æ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ–π! –£—Å–ø–µ–π—Ç–µ –∫—É–ø–∏—Ç—å:\n‚Ä¢ –°–µ—Ä–≤–µ—Ä—ã\n‚Ä¢ –°–µ—Ç–µ–≤–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ\n‚Ä¢ –ö–æ–º–ø—å—é—Ç–µ—Ä—ã\n\n–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏: http://sale.hardware.ru"
            ],
            "–õ–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ": [
                "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞? –î–∞–≤–Ω–æ –Ω–µ –≤–∏–¥–µ–ª–∏—Å—å. üòä\n\n–ü—Ä–µ–¥–ª–∞–≥–∞—é –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å—Å—è –≤ —Å—É–±–±–æ—Ç—É –≤ 18:00 –≤ –Ω–∞—à–µ–º –ª—é–±–∏–º–æ–º –∫–∞—Ñ–µ '–£ –§—Ä–∞–Ω—Å—É–∞'.\n\n–ü–æ–∑–≤–æ–Ω–∏ –º–Ω–µ, —á—Ç–æ–±—ã –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å.\n\n–û–±–Ω–∏–º–∞—é!\n–ú–∞—à–∞",
                "–ü—Ä–∏–≤–µ—Ç, –¥—Ä—É–≥! –ü–æ—Å–º–æ—Ç—Ä–∏ —ç—Ç–æ –≤–∏–¥–µ–æ, –æ—á–µ–Ω—å —Å–º–µ—à–Ω–æ–µ: https://youtube.com/watch?v=abcdef\n\n–ö–∞–∫ —Ç–≤–æ–π –ø—Ä–æ–µ–∫—Ç? –£ –º–µ–Ω—è –≤—Å—ë –æ–∫, –≥–æ—Ç–æ–≤–ª—é—Å—å –∫ –æ—Ç–ø—É—Å–∫—É.\n\n–í–µ—á–µ—Ä–æ–º –ø–µ—Ä–µ–∑–≤–æ–Ω—é!",
                "–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ! ‚òï\n\n–û—Ç–ø—Ä–∞–≤–∏–ª —Ç–µ–±–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –ø—Ä–æ–µ–∫—Ç—É. –ü–æ—Å–º–æ—Ç—Ä–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –≤—Ä–µ–º—è.\n\n–•–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è!\n–ö–æ–ª–ª–µ–≥–∞"
            ]
        }
        
        # –°–æ–∑–¥–∞—ë–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ –¥–µ–º–æ-—Ñ–∞–π–ª—ã
        demo_data = []
        for i in range(1, 101):  # 100 –¥–µ–º–æ-–ø–∏—Å–µ–º
            categories = list(category_templates.keys())
            category = categories[(i-1) % len(categories)]
            template = random.choice(category_templates[category])
            
            demo_data.append({
                'filename': f'{i:03d}_{category.replace(" ", "_").replace("/", "-")}.txt',
                'true_category': category
            })
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            filepath = self.test_emails_dir / demo_data[-1]['filename']
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(template)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º labels
        df = pd.DataFrame(demo_data)
        labels_path = self.test_emails_dir / "labels.csv"
        df.to_csv(labels_path, index=False, encoding='utf-8-sig')
        
        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        stats = {
            "total_emails": len(demo_data),
            "categories": {cat: sum(1 for d in demo_data if d['true_category'] == cat) 
                          for cat in category_templates.keys()},
            "created_at": datetime.now().isoformat(),
            "avg_text_length": np.mean([len(t) for templates in category_templates.values() for t in templates])
        }
        
        stats_path = self.test_emails_dir / "dataset_info.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        st.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(demo_data)} —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –¥–µ–º–æ-–ø–∏—Å–µ–º –≤ –ø–∞–ø–∫–µ {self.test_emails_dir}")
    
    def load_test_emails(self, limit: int = None, shuffle: bool = True) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø–∏—Å–µ–º —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        labels_path = self.test_emails_dir / "labels.csv"
        
        if not labels_path.exists():
            st.error(f"‚ùå –§–∞–π–ª labels.csv –Ω–µ –Ω–∞–π–¥–µ–Ω: {labels_path.absolute()}")
            return []
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
            df_labels = pd.read_csv(labels_path, encoding='utf-8-sig')
            
            if shuffle:
                df_labels = df_labels.sample(frac=1, random_state=42).reset_index(drop=True)
            
            if limit and limit < len(df_labels):
                df_labels = df_labels.head(limit)
            
            emails = []
            stats = {
                'total': len(df_labels),
                'loaded': 0,
                'failed': 0,
                'categories': {}
            }
            
            for idx, row in df_labels.iterrows():
                filename = str(row["filename"]).strip()
                true_cat = str(row["true_category"]).strip()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                if true_cat not in stats['categories']:
                    stats['categories'][true_cat] = 0
                stats['categories'][true_cat] += 1
                
                # –ò—â–µ–º —Ñ–∞–π–ª
                file_found = False
                content = ""
                
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏
                possible_paths = [
                    self.test_emails_dir / filename,
                    self.test_emails_dir / f"{Path(filename).stem}.txt",
                    self.test_emails_dir / f"{Path(filename).stem}.eml",
                ]
                
                for file_path in possible_paths:
                    if file_path.exists():
                        try:
                            # –ß–∏—Ç–∞–µ–º —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏
                            with open(file_path, 'rb') as f:
                                raw_content = f.read()
                            
                            # –ü—Ä–æ–±—É–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å
                            for encoding in ['utf-8', 'utf-8-sig', 'cp1251', 'windows-1251', 'latin-1']:
                                try:
                                    content = raw_content.decode(encoding, errors='ignore')
                                    break
                                except:
                                    continue
                            
                            if content:
                                file_found = True
                                break
                        except Exception as e:
                            continue
                
                if not file_found:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    template_bank = {
                        "–î–µ–ª–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ": "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–µ –≤ —Å—Ñ–µ—Ä–µ IT —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏. –ì–æ—Ç–æ–≤—ã –æ–±—Å—É–¥–∏—Ç—å —É—Å–ª–æ–≤–∏—è –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.",
                        "–ñ–∞–ª–æ–±–∞ –∫–ª–∏–µ–Ω—Ç–∞": "–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –∂–∞–ª–æ–±–∞ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è. –¢—Ä–µ–±—É–µ—Ç—Å—è —Å—Ä–æ—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è —É—â–µ—Ä–±–∞.",
                        "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞": "–ó–∞–ø—Ä–æ—Å –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É. –ü—Ä–æ–±–ª–µ–º–∞ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ —Å–∏—Å—Ç–µ–º–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –ø–æ–º–æ—â—å —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞.",
                        "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å": "–ó–∞–ø—Ä–æ—Å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —É—Ç–æ—á–Ω–µ–Ω–∏–µ —É—Å–ª–æ–≤–∏–π –æ–ø–ª–∞—Ç—ã –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É.",
                        "–°–ø–∞–º / –†–µ–∫–ª–∞–º–∞": "–°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ! –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –∞–∫—Ü–∏—è —Å–æ —Å–∫–∏–¥–∫–∞–º–∏!",
                        "HR / –†–µ–∫—Ä—É—Ç–∏–Ω–≥": "–ü—Ä–∏–≥–ª–∞—à–µ–Ω–∏–µ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ. –û–±—Å—É–∂–¥–µ–Ω–∏–µ —É—Å–ª–æ–≤–∏–π —Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞.",
                        "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ø–∏—Å—å–º–æ": "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤.",
                        "–ù–æ–≤–æ—Å—Ç–∏ / –ê–Ω–æ–Ω—Å—ã": "–ê–Ω–æ–Ω—Å –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –∏ –≤–∞–∂–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.",
                        "–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ / –ü—Ä–æ–¥–∞–∂–∏": "–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤.",
                        "–õ–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ": "–ù–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –∫–æ–ª–ª–µ–≥–∏ –∏–ª–∏ –∑–Ω–∞–∫–æ–º–æ–≥–æ."
                    }
                    content = template_bank.get(true_cat, f"–¢–µ–∫—Å—Ç –ø–∏—Å—å–º–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {true_cat}")
                    stats['failed'] += 1
                else:
                    stats['loaded'] += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
                if len(content.strip()) < self.config["min_text_length"]:
                    content = content + "\n" + "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ."
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
                if len(content) > self.config["max_text_length"]:
                    content = content[:self.config["max_text_length"]] + "..."
                
                emails.append({
                    "filename": filename,
                    "true_category": true_cat,
                    "text": content,
                    "length": len(content),
                    "words": len(content.split()),
                    "loaded_from_file": file_found
                })
            
            # –û—Ç—á—ë—Ç –æ –∑–∞–≥—Ä—É–∑–∫–µ
            report = f"""
            üìä –û—Ç—á—ë—Ç –æ –∑–∞–≥—Ä—É–∑–∫–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:
            ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']}
            ‚Ä¢ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {stats['loaded']}
            ‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —à–∞–±–ª–æ–Ω—ã: {stats['failed']}
            ‚Ä¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {len(stats['categories'])}
            """
            
            st.info(report)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._save_loading_stats(stats)
            
            return emails
            
        except Exception as e:
            st.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {str(e)[:200]}")
            return []
    
    def _save_loading_stats(self, stats: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏"""
        stats_file = self.logs_dir / "loading_stats.json"
        
        if stats_file.exists():
            with open(stats_file, 'r', encoding='utf-8') as f:
                existing_stats = json.load(f)
        else:
            existing_stats = []
        
        existing_stats.append({
            "timestamp": datetime.now().isoformat(),
            **stats
        })
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(existing_stats, f, ensure_ascii=False, indent=2)
    
    def run_classification_benchmark(self, classifier, num_emails: int = 100, 
                                    detailed_analysis: bool = True) -> pd.DataFrame:
        """–ó–∞–ø—É—Å–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∏—Å—å–º–∞
        emails = self.load_test_emails(num_emails)
        
        if not emails:
            st.error("‚ùå –ù–µ—Ç –ø–∏—Å–µ–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return pd.DataFrame()
        
        results = []
        start_time = time.time()
        
        # –°–æ–∑–¥–∞—ë–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        progress_container = st.container()
        status_container = st.container()
        metrics_container = st.container()
        
        with progress_container:
            st.markdown("### üöÄ –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞")
            progress_bar = st.progress(0)
            status_text = st.empty()
            metrics_text = st.empty()
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        processing_times = []
        confidences = []
        
        for i, email in enumerate(emails):
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            status_text.text(f"üìß –û–±—Ä–∞–±–æ—Ç–∫–∞ {i+1}/{len(emails)}: {email['filename'][:30]}...")
            
            # –ó–∞–º–µ—Ä –≤—Ä–µ–º–µ–Ω–∏
            iteration_start = time.perf_counter()
            
            try:
                # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
                if hasattr(classifier, 'set_threshold'):
                    classifier.set_threshold(self.config["default_threshold"])
                
                prediction = classifier.classify(email["text"], top_n=3, use_cache=self.config["cache_enabled"])
                
                # –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                duration = (time.perf_counter() - iteration_start) * 1000
                processing_times.append(duration)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
                predicted_cat = prediction.get("predicted_category", "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞")
                true_cat = email["true_category"]
                is_undefined = prediction.get("is_undefined", False)
                confidence = prediction.get("confidence", 0.0)
                confidences.append(confidence)
                
                # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                is_correct = self._enhanced_category_match(predicted_cat, true_cat, is_undefined)
                
                # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                result = {
                    "filename": email["filename"],
                    "true_category": true_cat,
                    "predicted_category": predicted_cat,
                    "confidence": confidence,
                    "is_undefined": is_undefined,
                    "time_ms": round(duration, 1),
                    "is_correct": is_correct,
                    "success": True,
                    "text_length": email["length"],
                    "word_count": email["words"],
                    "method": prediction.get("method", "unknown"),
                    "top_categories": json.dumps(prediction.get("top_categories", []), ensure_ascii=False),
                    "all_scores": json.dumps(prediction.get("all_scores", {}), ensure_ascii=False) if prediction.get("all_scores") else "{}"
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                if confidence > 0.7:
                    result["confidence_level"] = "high"
                elif confidence > 0.4:
                    result["confidence_level"] = "medium"
                else:
                    result["confidence_level"] = "low"
                
                results.append(result)
                
            except Exception as e:
                duration = (time.perf_counter() - iteration_start) * 1000
                results.append({
                    "filename": email["filename"],
                    "true_category": email["true_category"],
                    "predicted_category": "ERROR",
                    "confidence": 0.0,
                    "is_undefined": True,
                    "time_ms": round(duration, 1),
                    "is_correct": False,
                    "success": False,
                    "error": str(e)[:100],
                    "text_length": email["length"],
                    "word_count": email["words"]
                })
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –º–µ—Ç—Ä–∏–∫–∏
            progress = (i + 1) / len(emails)
            progress_bar.progress(progress)
            
            if i % 10 == 0:  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 10 –∏—Ç–µ—Ä–∞—Ü–∏–π
                current_metrics = self._calculate_intermediate_metrics(results, processing_times)
                metrics_text.text(
                    f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i+1}/{len(emails)}\n"
                    f"üìä –¢–æ—á–Ω–æ—Å—Ç—å: {current_metrics.get('accuracy', 0):.1%}\n"
                    f"‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {current_metrics.get('avg_time_ms', 0):.1f} –º—Å"
                )
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        total_time = time.time() - start_time
        status_text.text(f"‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à—ë–Ω –∑–∞ {total_time:.1f} —Å–µ–∫—É–Ω–¥")
        time.sleep(0.5)
        progress_bar.empty()
        status_text.empty()
        
        # –°–æ–∑–¥–∞—ë–º DataFrame
        df = pd.DataFrame(results)
        
        if detailed_analysis and not df.empty:
            self._perform_detailed_analysis(df, emails)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._save_benchmark_results(df, total_time)
        
        return df
    
    def _enhanced_category_match(self, predicted: str, true: str, is_undefined: bool) -> bool:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        pred_norm = predicted.lower().strip()
        true_norm = true.lower().strip()
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if pred_norm == true_norm:
            return True
        
        # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        pred_words = set([w for w in pred_norm.split() if len(w) > 2])
        true_words = set([w for w in true_norm.split() if len(w) > 2])
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if pred_words.intersection(true_words):
            return True
        
        # –°–∏–Ω–æ–Ω–∏–º—ã –∏ –ø–æ—Ö–æ–∂–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        synonym_groups = [
            ["–¥–µ–ª–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ", "–∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ", "–±–∏–∑–Ω–µ—Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"],
            ["–∂–∞–ª–æ–±–∞ –∫–ª–∏–µ–Ω—Ç–∞", "–ø—Ä–µ—Ç–µ–Ω–∑–∏—è", "—Ä–µ–∫–ª–∞–º–∞—Ü–∏—è"],
            ["—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞", "—Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞", "–ø–æ–¥–¥–µ—Ä–∂–∫–∞"],
            ["—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å", "—Ñ–∏–Ω–∞–Ω—Å—ã", "—Å—á—ë—Ç", "–æ–ø–ª–∞—Ç–∞"],
            ["—Å–ø–∞–º / —Ä–µ–∫–ª–∞–º–∞", "—Å–ø–∞–º", "—Ä–µ–∫–ª–∞–º–∞", "—Ä–∞—Å—Å—ã–ª–∫–∞"],
            ["hr / —Ä–µ–∫—Ä—É—Ç–∏–Ω–≥", "–∫–∞–¥—Ä—ã", "—Ä–µ–∫—Ä—É—Ç–∏–Ω–≥", "–≤–∞–∫–∞–Ω—Å–∏—è"],
            ["—é—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ø–∏—Å—å–º–æ", "—é—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ", "–¥–æ–≥–æ–≤–æ—Ä"],
            ["–Ω–æ–≤–æ—Å—Ç–∏ / –∞–Ω–æ–Ω—Å—ã", "–Ω–æ–≤–æ—Å—Ç–∏", "–∞–Ω–æ–Ω—Å", "–æ–±—ä—è–≤–ª–µ–Ω–∏–µ"],
            ["–º–∞—Ä–∫–µ—Ç–∏–Ω–≥ / –ø—Ä–æ–¥–∞–∂–∏", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "–ø—Ä–æ–¥–∞–∂–∏"],
            ["–ª–∏—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ", "–ª–∏—á–Ω–æ–µ", "–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω–æ–µ"]
        ]
        
        for group in synonym_groups:
            if any(word in pred_norm for word in group) and any(word in true_norm for word in group):
                return True
        
        # –î–ª—è "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞" –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if ("–Ω–µ –æ–ø—Ä–µ–¥–µ–ª" in true_norm or "undefined" in true_norm) and is_undefined:
            return True
        
        return False
    
    def _calculate_intermediate_metrics(self, results: List[Dict], processing_times: List[float]) -> Dict:
        """–†–∞—Å—á—ë—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        if not results:
            return {}
        
        df_temp = pd.DataFrame(results)
        
        correct = df_temp["is_correct"].sum() if "is_correct" in df_temp.columns else 0
        total = len(df_temp)
        
        return {
            "accuracy": correct / total if total > 0 else 0.0,
            "avg_time_ms": np.mean(processing_times) if processing_times else 0.0,
            "processed": total
        }
    
    def _perform_detailed_analysis(self, df: pd.DataFrame, emails: List[Dict]):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if df.empty:
            return
        
        st.markdown("## üìä –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = self.calculate_enhanced_metrics(df)
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            accuracy = metrics["accuracy"]
            color = "green" if accuracy > 0.7 else "orange" if accuracy > 0.5 else "red"
            st.metric("üéØ –¢–æ—á–Ω–æ—Å—Ç—å", f"{accuracy:.1%}", delta_color="off")
            st.markdown(f"<p style='color:{color};font-weight:bold'>–ü—Ä–∞–≤–∏–ª—å–Ω–æ: {metrics['correct_predictions']}/{metrics['total_emails']}</p>", unsafe_allow_html=True)
        
        with col2:
            st.metric("‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", f"{metrics['avg_time_ms']:.1f} –º—Å")
            st.caption(f"–ú–∏–Ω: {metrics['min_time_ms']:.1f} –º—Å, –ú–∞–∫—Å: {metrics['max_time_ms']:.1f} –º—Å")
        
        with col3:
            st.metric("‚ùì –ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ", f"{metrics['undefined_rate']:.1f}%")
            st.caption(f"–í—Å–µ–≥–æ: {metrics['undefined_count']} –ø–∏—Å–µ–º")
        
        with col4:
            st.metric("üìà –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{metrics['avg_confidence']:.1%}")
            st.caption(f"–í—ã—Å–æ–∫–∞—è: {metrics.get('high_confidence_pct', 0):.1f}%")
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
        st.markdown("### üìã –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞")
        
        # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–∏–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        tab1, tab2, tab3, tab4 = st.tabs(["üìä –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º", "üìà –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏", "üé≠ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫", "üìù –ü—Ä–∏–º–µ—Ä—ã"])
        
        with tab1:
            self._show_category_analysis(df)
        
        with tab2:
            self._show_time_analysis(df)
        
        with tab3:
            self._show_confusion_matrix(df)
        
        with tab4:
            self._show_examples(df, emails)
    
    def _show_category_analysis(self, df: pd.DataFrame):
        """–ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        if "true_category" not in df.columns:
            return
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_stats = df.groupby("true_category").agg({
            "is_correct": ["count", "sum", "mean"],
            "confidence": ["mean", "std"],
            "time_ms": ["mean", "median"]
        }).round(3)
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
        category_stats.columns = [
            "total", "correct", "accuracy",
            "avg_conf", "std_conf",
            "avg_time", "median_time"
        ]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        category_stats["accuracy_pct"] = (category_stats["accuracy"] * 100).round(1)
        category_stats["avg_conf_pct"] = (category_stats["avg_conf"] * 100).round(1)
        
        st.dataframe(category_stats, use_container_width=True)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        if len(category_stats) > 1:
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=("–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º", "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º",
                              "–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"),
                vertical_spacing=0.15
            )
            
            # 1. –¢–æ—á–Ω–æ—Å—Ç—å
            fig.add_trace(
                go.Bar(
                    x=category_stats.index,
                    y=category_stats["accuracy_pct"],
                    name="–¢–æ—á–Ω–æ—Å—Ç—å",
                    marker_color='lightblue',
                    text=category_stats["accuracy_pct"].apply(lambda x: f"{x:.1f}%"),
                    textposition='auto'
                ),
                row=1, col=1
            )
            fig.update_xaxes(title_text="–ö–∞—Ç–µ–≥–æ—Ä–∏—è", row=1, col=1)
            fig.update_yaxes(title_text="–¢–æ—á–Ω–æ—Å—Ç—å (%)", row=1, col=1)
            
            # 2. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            fig.add_trace(
                go.Bar(
                    x=category_stats.index,
                    y=category_stats["avg_conf_pct"],
                    name="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å",
                    marker_color='lightgreen',
                    text=category_stats["avg_conf_pct"].apply(lambda x: f"{x:.1f}%"),
                    textposition='auto'
                ),
                row=1, col=2
            )
            fig.update_xaxes(title_text="–ö–∞—Ç–µ–≥–æ—Ä–∏—è", row=1, col=2)
            fig.update_yaxes(title_text="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (%)", row=1, col=2)
            
            # 3. –í—Ä–µ–º—è
            fig.add_trace(
                go.Bar(
                    x=category_stats.index,
                    y=category_stats["avg_time"],
                    name="–í—Ä–µ–º—è (–º—Å)",
                    marker_color='orange',
                    text=category_stats["avg_time"].apply(lambda x: f"{x:.1f}"),
                    textposition='auto'
                ),
                row=2, col=1
            )
            fig.update_xaxes(title_text="–ö–∞—Ç–µ–≥–æ—Ä–∏—è", row=2, col=1)
            fig.update_yaxes(title_text="–í—Ä–µ–º—è (–º—Å)", row=2, col=1)
            
            # 4. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
            fig.add_trace(
                go.Scatter(
                    x=category_stats.index,
                    y=category_stats["correct"],
                    mode='lines+markers',
                    name="–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ",
                    line=dict(color='red', width=2),
                    marker=dict(size=10)
                ),
                row=2, col=2
            )
            fig.update_xaxes(title_text="–ö–∞—Ç–µ–≥–æ—Ä–∏—è", row=2, col=2)
            fig.update_yaxes(title_text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", row=2, col=2)
            
            fig.update_layout(height=600, showlegend=False, title_text="–ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
            st.plotly_chart(fig, use_container_width=True)
    
    def _show_time_analysis(self, df: pd.DataFrame):
        """–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if "time_ms" not in df.columns:
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –≤—Ä–µ–º–µ–Ω–∏
            fig = px.histogram(
                df, x="time_ms",
                nbins=20,
                title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏",
                labels={"time_ms": "–í—Ä–µ–º—è (–º—Å)"},
                color_discrete_sequence=['skyblue']
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Box plot –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            if "true_category" in df.columns:
                fig = px.box(
                    df, x="true_category", y="time_ms",
                    title="–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º",
                    labels={"true_category": "–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "time_ms": "–í—Ä–µ–º—è (–º—Å)"}
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è
        numeric_cols = ["time_ms", "confidence", "text_length"]
        available_cols = [col for col in numeric_cols if col in df.columns]
        
        if available_cols:
            st.markdown("#### üìà –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ—Ç—Ä–∏–∫")
            numeric_df = df[available_cols].apply(pd.to_numeric, errors='coerce')
            
            if not numeric_df.empty and len(available_cols) > 1:
                corr = numeric_df.corr()
                
                fig = px.imshow(
                    corr,
                    text_auto=True,
                    color_continuous_scale='RdBu',
                    title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞"
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)
    
    def _show_confusion_matrix(self, df: pd.DataFrame):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫"""
        if "true_category" not in df.columns or "predicted_category" not in df.columns:
            return
        
        # –°–æ–∑–¥–∞—ë–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫
        y_true = df["true_category"]
        y_pred = df["predicted_category"]
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        categories = sorted(set(y_true.unique()) | set(y_pred.unique()))
        
        # –°–æ–∑–¥–∞—ë–º –º–∞—Ç—Ä–∏—Ü—É
        confusion_data = []
        for true_cat in categories:
            for pred_cat in categories:
                count = len(df[(df["true_category"] == true_cat) & (df["predicted_category"] == pred_cat)])
                if count > 0:
                    confusion_data.append({
                        "–ò—Å—Ç–∏–Ω–Ω–∞—è": true_cat,
                        "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è": pred_cat,
                        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": count
                    })
        
        confusion_df = pd.DataFrame(confusion_data)
        
        if not confusion_df.empty:
            # Heatmap
            fig = px.density_heatmap(
                confusion_df,
                x="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è",
                y="–ò—Å—Ç–∏–Ω–Ω–∞—è",
                z="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ",
                color_continuous_scale="Viridis",
                title="–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫",
                text_auto=True
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
            
            # –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –æ—à–∏–±–æ–∫
            st.markdown("#### üîç –û—Å–Ω–æ–≤–Ω—ã–µ –æ—à–∏–±–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            
            # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏
            errors = confusion_df[
                (confusion_df["–ò—Å—Ç–∏–Ω–Ω–∞—è"] != confusion_df["–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è"]) &
                (confusion_df["–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è"] != "ERROR")
            ].sort_values("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", ascending=False).head(10)
            
            if not errors.empty:
                st.dataframe(errors, use_container_width=True)
    
    def _show_examples(self, df: pd.DataFrame, emails: List[Dict]):
        """–ü–æ–∫–∞–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        st.markdown("#### ‚úÖ –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        
        correct_examples = df[df["is_correct"] == True].head(3)
        for _, row in correct_examples.iterrows():
            email = next((e for e in emails if e["filename"] == row["filename"]), None)
            if email:
                with st.expander(f"‚úÖ {row['filename']} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {row['confidence']:.1%})"):
                    st.write(f"**–ò—Å—Ç–∏–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è:** {row['true_category']}")
                    st.write(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è:** {row['predicted_category']}")
                    st.write(f"**–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞:** {row['text_length']} —Å–∏–º–≤–æ–ª–æ–≤")
                    st.write(f"**–¢–µ–∫—Å—Ç (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤):**")
                    st.text(email['text'][:300] + "...")
        
        st.markdown("#### ‚ùå –ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        
        error_examples = df[(df["is_correct"] == False) & (df["success"] == True)].head(3)
        for _, row in error_examples.iterrows():
            email = next((e for e in emails if e["filename"] == row["filename"]), None)
            if email:
                with st.expander(f"‚ùå {row['filename']} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {row['confidence']:.1%})"):
                    st.write(f"**–ò—Å—Ç–∏–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è:** {row['true_category']}")
                    st.write(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è:** {row['predicted_category']}")
                    st.write(f"**–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞:** {row['text_length']} —Å–∏–º–≤–æ–ª–æ–≤")
                    if row["is_undefined"]:
                        st.warning("üì≠ –ü–∏—Å—å–º–æ –ø–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ '–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ'")
                    st.write(f"**–¢–µ–∫—Å—Ç (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤):**")
                    st.text(email['text'][:300] + "...")
    
    def _save_benchmark_results(self, df: pd.DataFrame, total_time: float):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–∞"""
        if df.empty:
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_path = self.logs_dir / f"benchmark_results_{timestamp}.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = self.calculate_enhanced_metrics(df)
        metrics["total_time_seconds"] = total_time
        metrics["timestamp"] = timestamp
        
        metrics_path = self.logs_dir / f"benchmark_metrics_{timestamp}.json"
        with open(metrics_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.results_history.append({
            "timestamp": timestamp,
            "metrics": metrics,
            "file_path": str(csv_path)
        })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        history_path = self.logs_dir / "benchmark_history.json"
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(self.results_history, f, ensure_ascii=False, indent=2)
        
        st.success(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        st.info(f"‚Ä¢ CSV: `{csv_path}`\n‚Ä¢ –ú–µ—Ç—Ä–∏–∫–∏: `{metrics_path}`\n‚Ä¢ –ò—Å—Ç–æ—Ä–∏—è: `{history_path}`")
    
    def calculate_enhanced_metrics(self, df: pd.DataFrame) -> Dict:
        """–†–∞—Å—á—ë—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        if df.empty:
            return {}
        
        total = len(df)
        correct = df["is_correct"].sum() if "is_correct" in df.columns else 0
        undefined = df["is_undefined"].sum() if "is_undefined" in df.columns else 0
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = {
            "accuracy": correct / total if total > 0 else 0.0,
            "avg_time_ms": df["time_ms"].mean() if "time_ms" in df.columns else 0.0,
            "min_time_ms": df["time_ms"].min() if "time_ms" in df.columns else 0.0,
            "max_time_ms": df["time_ms"].max() if "time_ms" in df.columns else 0.0,
            "undefined_rate": (undefined / total) * 100 if total > 0 else 0.0,
            "undefined_count": int(undefined),
            "total_emails": total,
            "correct_predictions": int(correct),
            "error_rate": ((total - correct - undefined) / total) * 100 if total > 0 else 0.0,
            "success_rate": (df["success"].sum() / total) * 100 if "success" in df.columns else 0.0
        }
        
        # –ú–µ—Ç—Ä–∏–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if "confidence" in df.columns:
            conf_series = pd.to_numeric(df["confidence"], errors='coerce')
            if not conf_series.empty:
                metrics.update({
                    "avg_confidence": conf_series.mean(),
                    "min_confidence": conf_series.min(),
                    "max_confidence": conf_series.max(),
                    "high_confidence_count": (conf_series > 0.7).sum(),
                    "medium_confidence_count": ((conf_series > 0.4) & (conf_series <= 0.7)).sum(),
                    "low_confidence_count": (conf_series <= 0.4).sum(),
                })
                metrics["high_confidence_pct"] = (metrics["high_confidence_count"] / total) * 100
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        if "true_category" in df.columns and "is_correct" in df.columns:
            category_acc = df.groupby("true_category")["is_correct"].mean()
            if not category_acc.empty:
                metrics["best_category"] = category_acc.idxmax()
                metrics["best_category_acc"] = category_acc.max()
                metrics["worst_category"] = category_acc.idxmin()
                metrics["worst_category_acc"] = category_acc.min()
        
        return metrics
    
    def get_benchmark_history(self) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤"""
        history_path = self.logs_dir / "benchmark_history.json"
        
        if history_path.exists():
            try:
                with open(history_path, 'r', encoding='utf-8') as f:
                    history = json.load(f)
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
                history_data = []
                for entry in history:
                    if "metrics" in entry:
                        row = {"timestamp": entry["timestamp"]}
                        row.update(entry["metrics"])
                        history_data.append(row)
                
                return pd.DataFrame(history_data)
            except:
                return pd.DataFrame()
        
        return pd.DataFrame()
    
    def run_benchmarks(self, classifier, n_emails: int = 100, detailed: bool = True):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤"""
        return self.run_classification_benchmark(classifier, n_emails, detailed)
    
    def get_detailed_statistics(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü–æ–¥—Ä–æ–±–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        if df.empty or "true_category" not in df.columns:
            return pd.DataFrame()
        
        stats = df.groupby("true_category").agg({
            "is_correct": ["count", "sum", "mean"],
            "confidence": ["mean", "std", "min", "max"],
            "time_ms": ["mean", "median", "std"],
            "is_undefined": ["sum", "mean"]
        }).round(3)
        
        stats.columns = [
            "total", "correct", "accuracy",
            "avg_conf", "std_conf", "min_conf", "max_conf",
            "avg_time", "median_time", "std_time",
            "undefined_count", "undefined_rate"
        ]
        
        stats["accuracy"] = stats["accuracy"].apply(lambda x: f"{x:.1%}")
        stats["avg_conf"] = stats["avg_conf"].apply(lambda x: f"{x:.1%}")
        stats["undefined_rate"] = stats["undefined_rate"].apply(lambda x: f"{x:.1%}")
        
        return stats

# –≠–∫—Å–ø–æ—Ä—Ç –∫–ª–∞—Å—Å–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
ModelBenchmark = EnhancedModelBenchmark